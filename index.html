<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129673183-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129673183-1');
</script>

  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <title>Shruti Bhargava</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Bio and Image -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="80%" valign="middle">
              <p align="center">
                <name>Shruti Bhargava</name>
              </p>
	      <p>&nbsp;</p>
              <p align="justify">
	      	I work as an ML Engineer at Apple in the Siri And Language Technologies team. I completed Masters in Computer Science from University of Illinois at Urbana-Champaign (UIUC), advised by <a href="http://luthuli.cs.uiuc.edu/~daf/"> Prof. David Forsyth</a>. I completed Bachelors in Computer Science from IIT Kanpur, India. 
	      </p>
	      <p align="justify"> 
	      	I have been fortunate to work with inspiring researchers.
	        <ul>
            <li><i> Fall 2017: </i> Coordinated Science Laboratory, UIUC with <a href="http://pramodv.ece.illinois.edu"> Prof. Pramod Viswanath </a>
            <li><i> Fall 2016: </i> IIT Kanpur with <a href="https://www.cse.iitk.ac.in/users/purushot/"> Prof. Purushottam Kar</a>
	          <li> <i>Summer 2016: </i> Microsoft Research with  <a href="https://www.microsoft.com/en-us/research/people/nagarajn/"> Dr. Nagarajan Natarajan</a>
	          <li> <i>Summer 2015: </i> Max Planck Institute for Informatics with <a href="https://en.wikipedia.org/wiki/Kurt_Mehlhorn">Prof. Kurt Mehlhorn</a> and <a href = "https://www.cmi.ac.in/~gphilip/">Dr. Geevarghese Philip </a>
	        </ul>
              </p>
	      <p align="justify"> <strong> 
	        Awards and Scholarships: </strong>
	        <ul>
	      <li> Recipient of Grace Hopper Student Scholarship  by Anita Borg Institute.
        <li> Recipient of Academic Excellence Award by IIT Kanpur.   
			  <li> National Talent Search (NTS) Scholar by Govt. of India.
			  <li> Kishore Vaigyanik Protsahan Yojana (KVPY)  Scholar by Dept. of Science and Technology, Govt. of India.
			  
	        </ul>
              </p>
              <p align="justify">
          I am interested in building fair and impactful solutions using Machine Learning. Particularly, I aim to develop technology at the intersection of Natural Language and Computer Vision to assist the society. 
        </p>
	    </td>

            <td width="20%">
              <img src="images/self.png" width="100%">
            </td>
          </tr>
	  <tr>
            <td colspan="2">
              <p align=center margin=0px>
                <a href="mailto:bharshruti@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=7Kl9w-sAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shruti-bhargava-90202b105"> LinkedIn </a> &nbsp
             </p>
	     <p>&nbsp;</p>
	   </td>
	  </tr>
        </table>
	<div class = "row">
        <table width="100%" align="center" margin-top=100px>
            <tr>
              <td align="center" width="10%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/apple.png" width="100%">
              </td>

              <td align="center" width="18%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/uiuc.png" width="30%">
              </td>

              <td align="center" width="10%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/apple.png" width="100%">
              </td>

              <td align="center" width="18%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/csl.png" width="100%">
              </td>

              <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/msr.png" width="70%">
              </td>

              <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/mpii.png" width="100%">
              </td>

              <td align="center" width="14%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <img src = "images/iitk.png" width="60%">
              </td>

             
            </tr>

            <tr>
                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">ML Engineer<br>Apple Inc.<br>2019 - </td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">MS, CS<br>University of Illinois, Urbana-Champaign<br>2017 - 2019</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">Intern<br>Apple Inc.<br> Summer 2018</td>

                
                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">Research Assistant<br>Coordinated Science Lab<br>Fall 2017</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">Research Intern<br>Microsoft Research<br>Summer 2016</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">Research Fellow<br>Max Planck Institute for Informatics <br>Summer 2015</td>
		
                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1); font-size: 14px">BTech, CS<br>IIT Kanpur<br>2013 - 2017</td>
          </tr>

          </table>
      </div>

        <!-- Research Interest -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="100%" valign="middle">
        <heading>Publications</heading>
        
      </td>
    </tr>
        </table>

        <!-- Publications-->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
             <!-- SynthDST -->
          <tr>
            <td width="35%">
              <img src='images/dst.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2402.02285">
                  <papertitle>SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State Tracking</papertitle>
                </a>
                <br>
                Atharva Kulkarni, Bo-Hsiang Tseng, Joel Ruben Antony Moniz, Dhivya Piraviperumal, Hong Yu, <strong>Shruti Bhargava</strong>
                <br>
                <em>EACL (Oral)</em> 2024
		            <br>
                <p align="justify">
Data generation framework that can efficiently generate synthetic data for dialogue schemas using countable templates. This bridges the gap between zero-shot and training data based few-shot prompting for dialog state tracking with LLMs.
            </p>
            </td>
          </tr>
             <!-- Context_LLM -->
          <tr>
            <td width="35%">
              <img src='images/gif_context.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/pdf/2402.00858">
                  <papertitle>Can Large Language Models Understand Context?</papertitle>
                </a>
                <br>
                Yilun Zhu, Joel Ruben Antony Moniz, <strong>Shruti Bhargava</strong>, Jiarui Lu, Dhivya Piraviperumal, Site Li, Yuan Zhang, Hong Yu, Bo-Hsiang Tseng
                <br>
                <em>EACL Findings</em> 2024
		            <br>
                <p align="justify">
A benchmark by adapting four tasks and nine existing datasets, featuring prompts designed to assess the context-understanding abilities of LLMs. In the ICL setting, models struggle with understanding nuanced contextual signals compared to SOTA fine-tuned models. Assessment of quantized models provides promising insights on the 3-bit post-training quantization.
            </p>
            </td>
          </tr>
      <!-- ScreenRef -->
          <tr>
            <td width="35%">
              <img src='images/screenref.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2306.07298">
                  <papertitle>Referring to Screen Texts with Voice Assistants</papertitle>
                </a>
                <br>
                <strong>Shruti Bhargava</strong>, Anand Dhoot, Ing-Marie Jonsson, Hoang Long Nguyen, Alkesh Patel, Hong Yu, Vincent Renkens
                <br>
                <em>ACL Industry Track</em> 2023
		            <br>
                <p align="justify">
Novel experience for users to refer to data-detectable entities on their phone screens when interacting with voice assistants. Screen reference resolution data strategy and a lightweight, general-purpose model that only uses the text extracted from the UI. The proposed model is modular, offering flexibility, better interpretability, and efficient run-time performance.
            </p>
            </td>
          </tr>
	  <!-- CREAD -->
          <tr>
            <td width="35%">
              <img src='images/cread.png' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://aclanthology.org/2021.naacl-main.265.pdf">
                  <papertitle>CREAD: Combined Resolution of Ellipses and Anaphora in Dialogues</papertitle>
                </a>
                <br>
                Bo-Hsiang Tseng, <strong>Shruti Bhargava</strong>, Jiarui Lu, Joel Ruben Antony Moniz, Dhivya Piraviperumal, Lin Li, Hong Yu
                <br>
                <em>NAACL</em> 2021                
		            <br>
                <a href="https://github.com/apple/ml-cread">[code]</a> 
                <p align="justify">
Resolving references and understanding ellipses are crucial for dialogue agents to generate coherent responses. A joint benchmark for the two tasks by annotating the dialogue-based coreference dataset, MuDoCo, with rewritten queries. A novel joint learning framework that boosts query rewrite and outperforms SOTA for coreference resolution.
	  <!-- DST Parsing -->
          <tr>
            <td width="35%">
              <img src='images/dst.png' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://aclanthology.org/2020.emnlp-main.651.pdf">
                  <papertitle>Conversational semantic parsing for dialog state tracking</papertitle>
                </a>
                <br>
                Jianpeng Chen, ... , <strong>Shruti Bhargava</strong>, ... , Jason D Williams, Hong Yu, Diarmuid O Seaghdha, Anders Johannsen
                <br>
                <em>EMNLP</em> 2020                
		            <br>
                <a href="https://github.com/apple/ml-tree-dst">[Dataset]</a> 
                <p align="justify">
Fresh perspective on dialog state tracking as a semantic parsing task over hierarchical representations, with compositionality, cross-domain knowledge sharing, and coreference. We present TreeDST, a dataset of 27k conversations with tree-structured states and system acts. Our encoder-decoder model leads to a 20% improvement over SOTA.
            </p>
            </td>
          </tr>
          
          <!-- Captioning Bias -->
          <tr>
            <td width="35%">
              <img src='images/gender_debias.gif' width=95%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7Kl9w-sAAAAJ&citation_for_view=7Kl9w-sAAAAJ:9yKSN-GCB0IC">
                  <papertitle>Exposing and Correcting the Gender Bias in Image Captioning Datasets and Models</papertitle>
                </a>
                <br>
                <strong>Shruti Bhargava</strong>, <a href = "https://scholar.google.com/citations?user=5H0arvkAAAAJ&hl=en"> David Forsyth </a>
                <br>
                <em>arxiv</em> 2019              
		            <br>
                <p align="justify">
The task of image captioning implicitly involves gender identification. MS COCO dataset contains blatant gender bias in captions, arising from two main sources: statistical variation in data and flawed annotations. Biased data leads to concerning predictions by models. We propose a novel framework for gender-neutral captioning and independent gender classification using masking, reducing contextual bias. On an anti-stereotypical dataset, our approach outperforms the SOTA gender-based approaches.

            </p>
            </td>
          </tr>

          <!-- Dandelion -->
          <tr>
            <td width="40%">
              <img src='images/dandelion.png' width="100%">
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://dl.acm.org/doi/pdf/10.1145/3224424">
                  <papertitle>Dandelion++ lightweight cryptocurrency networking with formal anonymity guarantees</papertitle>
                </a>
                <br>
                <a href="https://www.andrew.cmu.edu/user/gfanti/">Giulia Fanti</a>, Shaileshh Bojja Venkatakrishnan, Surya bakshi, Bradley Denby, <strong>Shruti Bhargava</strong>, <a href = "https://soc1024.ece.illinois.edu/"> Andrew Miller</a>, <a href="http://pramodv.ece.illinois.edu/">Pramod Viswanath</a>
                <br>
                <em>SIGMETRICS</em> 2018
                <br>
                <a href="t https://github.com/gfanti/dandelion-simulations.">[code]</a>
                <p align="justify">
Bitcoin's networking stack is shown to have anonymity vulnerabilities owing to the mechanism for broadcasting transactions, leading to large-scale deanonymization attacks. We present Dandelion++, a first-principles defense with near-optimal information-theoretic guarantees.            </p>
            </td>
          </tr>
        </table>

        <!-- Teaching -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Teaching</heading>
                <p>
                  I have been a Teaching Assistant for the following courses:
                    <ul>
                      <li> CS544: Optimization in Vision and AI  at UIUC [Spring 2019]</li>
                      <li> CS498: Applied Machine Learning at UIUC [Fall 2018] </li>
                      <li> CS374: Algorithms and Models of Computation at  UIUC [Spring 2018] </li>
                      <li> CS101: Introduction to Programming at IIT Kanpur [Spring 2017] </li>
                    </ul>
                </p>
              </td>
            </tr>
        </table>

        <!-- Reference -->
        <p align="right"><a href="https://jonbarron.info/">[Web Cite]</a></p>
      </td>
    </tr>
  </table>  

</body>

</html>
